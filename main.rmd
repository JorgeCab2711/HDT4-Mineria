---
title: "Hoja4_MD"
author: "Alejandra Guzman, Mariana David, Jorge Caballeros"
date: "2023-03-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
## Librerias utilizadas
library(dplyr)
library(ggplot2)
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(ggplot2) #para color
library(caret)
library(nortest)
library(tidyverse)
library(rpart) #para analisis de arbol
library(rpart.plot)

library(caret)
library(rpart)
library(rpart.plot)
```

# 1. Descargar los data/cargar los datay usar los mismos conjuntos de entrenamiento y prueba  
Guardaremos train en un objeto llamado data
```{r}
library(caret)
library(rpart)
library(rpart.plot)

# Cargando data
data <- read.csv('./train.csv') # nolint

# Separando datade entrenamiento y prueba
set.seed(456)
train_index <- createDataPartition(data$SalePrice, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]

# Seleccionando variables predictoras y variable objetivo
predictors <- c("OverallCond")
response <- "OverallQual"

# Entrenando el modelo de árbol de decisión
model <- rpart(as.formula(paste(response, "~", paste(predictors, collapse = "+"))), data = train_data, method = "class", control = rpart.control(maxdepth = 4)) # nolint

# Graficando el árbol de decisión
rpart.plot(model, type = 4, extra = 101, under = TRUE, main = "Árbol de decisión") # nolint

# Haciendo predicciones con los datade prueba
predictions <- predict(model, test_data, type = "class")

# Evaluando la precisión del modelo
confusion_matrix <- table(predictions, test_data[, response])
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Resultado de la precision del modelo principal: ", accuracy, "\n")
```

# 2. Elabore un árbol de regresión para predecir el precio de las casas usando todas las variables
```{r}
library(rpart)
# Seleccionando solo las columnas numéricas
X <- data[, sapply(data, is.numeric)] # nolint
# Reemplazando los NaN por ceros.
X[is.na(X)] <- 0 # nolint
y <- data$SalePrice # Variable a predecir.
y[is.na(y)] <- 0 # Quitando los NaN de y.
arbol <- rpart(SalePrice ~ ., data = X, method = "anova", control = rpart.control(maxdepth = 2))  # nolint
# Prediciendo los valores.
score <- summary(arbol)$cp[length(summary(arbol)$cp)]
cat("Precisión del arbol de regresión:", score)
rpart.plot(arbol, extra = 1) # Visualizando el árbol.
```

# 3. Úselo para predecir y analice el resultado. ¿Qué tal lo hizo? 
```{r}
# Prediciendo el precio con el árbol de decisión.
y <- data[, sapply(data, is.numeric)]
y[is.na(y)] <- 0 # Convirtiendo los NaN a número.
y_pred <- predict(arbol, newdata = y) # Prediciendo el precio.
cat("Predicción con máximo de divisiones 5 (profundidad): ") # nolint
head(y_pred, 3)
```
# 4. Haga, al menos, 3 modelos más cambiando el parámetro de la profundidad del árbol. ¿Cuál es el mejor modelo para predecir el precio de las casas? 
```{r}
# Creando el modelo de árbol con profundidad de 3.
arbol <- rpart(SalePrice ~ ., data = data, method = "anova", control = rpart.control(maxdepth = 3)) # nolint
rpart.plot(arbol, type = 0, extra = 0, under = TRUE, main = "Árbol de decisión (PROFUNDIDAD: 3)") # nolint
y_pred <- predict(arbol, newdata = data) # Prediciendo los valores
cat("Precisión del árbol con divisiones maximas de 3:") # nolint
head(y_pred, 5) #Mostrar soslo los primeros 5 valores

# Creando el modelo de árbol con profundidad de 4.
arbol <- rpart(SalePrice ~ ., data = data, method = "anova", control = rpart.control(maxdepth = 4)) # nolint
rpart.plot(arbol, type = 0, extra = 0, under = TRUE, main = "Árbol de decisión (PROFUNDIDAD: 4)") # nolint
y_pred <- predict(arbol, newdata = data)
cat("Precisión del árbol con divisiones maximas de 4:") # nolint
head(y_pred, 5)

# Creando el modelo del árbol con profundidad de 6.
arbol <- rpart(SalePrice ~ ., data = data, method = "anova", control = rpart.control(maxdepth = 6)) # nolint
rpart.plot(arbol, type = 0, extra = 0, under = TRUE, main = "Árbol de decisión (PROFUNDIDAD: 6)") # nolint
y_pred <- predict(arbol, newdata = data)
cat("Precisión del árbol con divisiones máximas de  6:") # nolint
head(y_pred, 5)

# Creando el modelo del árbol con profundidad de 8.
arbol <- rpart(SalePrice ~ ., data = data, method = "anova", control = rpart.control(maxdepth = 8)) # nolint
rpart.plot(arbol, type = 0, extra = 0, under = TRUE, main = "Árbol de decisión (PROFUNDIDAD: 8)") # nolint
y_pred <- predict(arbol, newdata = data)
cat("Precisión del árbol con divisiones máximas de 8:") # nolint
head(y_pred, 5)
```
# 5. Compare los resultados con el modelo de regresión lineal de la hoja anterior, ¿cuál lo hizo mejor? 
Comparando el resultado de predicción de ahora podemos afirmar que el modelo de regresion lineal nos dio un mejor resultado ya que predijo de manera mas rapida y simple la modelacion entre la variable respuesta que neceistabamos como el precio de las casa. 

#6. 

```{r include=FALSE}
    datos <- read.csv("train.csv")
    datos <- datos[ , !(names(datos) %in% c("Id","YrSold","MoSold","GarageYrBlt","MSSubClass","YearBuilt"))]
    Cuantitativas <- c("SalePrice", "LotFrontage", "LotArea", "OverallQual", "OverallCond", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal")
    df_cuantitativas <- datos[Cuantitativas]
    
       datos$LotFrontage[is.na(datos$LotFrontage)] <- median(datos$LotFrontage, na.rm = TRUE)
    datos$MasVnrArea[is.na(datos$MasVnrArea)] <- median(datos$MasVnrArea, na.rm = TRUE)
    datos <- datos[ , !(names(datos) %in% c("Alley", "PoolQC", "Fence", "MiscFeature","FireplaceQu"))]
    df_cuantitativas <- datos[Cuantitativas] 
    df_norm <- mutate_if(datos, is.numeric, scale)
    df_cualitativas <- df_norm[ , !(names(df_norm) %in% Cuantitativas)]
    for (i in 1:ncol(df_cualitativas)) {
         df_norm[,i] <- ifelse(is.na(df_norm[,i]), "Desconocido", df_norm[,i])
    }
    df_norm <- df_norm %>% mutate_at(colnames(df_cualitativas), function(x) as.factor(x))

```

```{r}
    salePrices <- df_norm$SalePrice
    q1 <- quantile(df_norm$SalePrice, 0.40)
    q2 <- quantile(df_norm$SalePrice, 0.60)
    df_norm$Classification <- sapply(df_norm$SalePrice, function(x) ifelse(x < q1, "cheap", ifelse(x < q2, "medium", "expensive")))
    df_norm$Classification <- factor(df_norm$Classification)
```

Se realizó una agrupación de los datos de la variable "SalePrice" para crear una nueva variable llamada "Classification". Se utilizaron los cuartiles de la variable "SalePrice" para separar los valores en tres categorías diferentes. Posteriormente, se utilizó la función sapply() para recorrer cada valor de la variable "SalePrice" y asignar la categoría correspondiente a la variable "Classification". Finalmente, se convirtió la variable "Classification" en un factor para facilitar su análisis.

#7 

```{r}

df_norm_w_SP <- df_norm[ , !(names(df_norm) %in% c("SalePrice"))]
df_norm_w_SP <- df_norm_w_SP[ ,c("Classification","Neighborhood","OverallQual","LotFrontage","MSZoning") ]

cheap <- df_norm_w_SP[df_norm_w_SP$Classification == "Economicas",]
medium <- df_norm_w_SP[df_norm_w_SP$Classification == "Intermedias",]
expensive <- df_norm_w_SP[df_norm_w_SP$Classification == "Caras",]
n_cheap <- nrow(cheap)
n_medium <- nrow(medium)
n_expensive <- nrow(expensive)
n_train_cheap <- round(n_cheap * 0.6)
n_train_medium <- round(n_medium * 0.6)
n_train_expensive <- round(n_expensive * 0.6)
train_cheap <- cheap[sample(n_cheap, n_train_cheap), ]
train_medium <- medium[sample(n_medium, n_train_medium), ]
train_expensive <- expensive[sample(n_expensive, n_train_expensive), ]
train2 <- rbind(train_cheap, train_medium, train_expensive)
test2 <- df_norm_w_SP[!rownames(df_norm_w_SP) %in% rownames(train2), ]

modelo4<- rpart(Classification~.,train2,method = "class",maxdepth=4)
rpart.plot(modelo4)


```
#8 y #9

Eficiencias

```{r}
    ypred <- predict(modelo4, newdata = test2)
    ypred<-apply(ypred, 1, function(x) colnames(ypred)[which.max(x)])
    ypred <- factor(ypred)
    recall_score <- Recall(test2$Classification, ypred,positive = c("Caras","Intermedias","Economicas"))
        confusionMatrix(ypred, test2$Classification)

```

La matriz de confusión muestra la cantidad de predicciones correctas e incorrectas para cada clase en un modelo de clasificación. En este caso, el modelo clasifica entre tres categorías: "Caras", "Economicas" e "Intermedias".

La tabla muestra que de las 234 instancias de la clase "Caras" en los datos de referencia, el modelo predijo correctamente 200 y se equivocó en 8 al predecir "Economicas" y en 34 al predecir "Intermedias". De las 309 instancias de la clase "Economicas", el modelo predijo correctamente 219, se equivocó en 20 al predecir "Caras" y en 70 al predecir "Intermedias". Finalmente, de las 33 instancias de la clase "Intermedias", el modelo predijo correctamente 14, se equivocó en 14 al predecir "Caras" y en 5 al predecir "Economicas".
