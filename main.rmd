---
title: "Hoja4_MD"
author: "Alejandra Guzman, Mariana David, Jorge Caballeros"
date: "2023-03-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
## Librerias utilizadas
library(dplyr)
library(ggplot2)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #revisa importancia de var
library(pheatmap) #Para hacer mapa de calor
library(ggplot2) #para color
library(caret)
library(nortest)
library(tidyverse)
library(ggpubr)
library(stats)
library(Metrics)
library(rpart) #para analisis de arbol
library(rpart.plot)
```

# 1. Descargar los datos/cargar los datos y usar los mismos conjuntos de entrenamiento y prueba  
Guardaremos train en un objeto llamado data
```{r}
library(caret)
library(rpart)
library(rpart.plot)

# Cargando datos
data <- read.csv('./train.csv')

# Separando datos de entrenamiento y prueba
set.seed(42)
train_index <- createDataPartition(data$SalePrice, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]

# Seleccionando variables predictoras y variable objetivo
predictors <- c("OverallCond")
response <- "OverallQual"

# Entrenando el modelo de árbol de decisión
model <- rpart(as.formula(paste(response, "~", paste(predictors, collapse = "+"))), data = train_data, method = "class", control = rpart.control(maxdepth = 4))

# Graficando el árbol de decisión
rpart.plot(model, type = 4, extra = 101, under = TRUE, main = "Árbol de decisión")

# Haciendo predicciones con los datos de prueba
predictions <- predict(model, test_data, type = "class")

# Evaluando la precisión del modelo
confusion_matrix <- table(predictions, test_data[, response])
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Resultado de la precision del modelo principal: ", accuracy, "\n")
```

# 2. Elabore un árbol de regresión para predecir el precio de las casas usando todas las variables
```{r}
# Seleccionando solo las columnas numéricas
X <- data[, sapply(data, is.numeric)]

# Reemplazando los NaN por ceros.
X[is.na(X)] <- 0

# Variable a predecir.
y <- data$SalePrice

# Quitando los NaN de y.
y[is.na(y)] <- 0

# Creando el árbol.
arbol <- rpart(y ~ ., data=X, method="anova", control=rpart.control(maxdepth=2))

# Ajustando el árbol.

# Prediciendo los valores.
score <- summary(arbol)$rsq

print("Precisión:", score)

# Visualizando el árbol.
rpart.plot(arbol, extra=1)

```

# 3. Úselo para predecir y analice el resultado. ¿Qué tal lo hizo? 
```{r}
# Prediciendo el precio con el árbol de decisión.

y <- data[,sapply(data, is.numeric)]

# Convirtiendo los NaN a número.
y[is.na(y)] <- 0

# Prediciendo el precio.
y_pred <- predict(arbol, newdata = y)

cat("Predicción con 5 de profundidad: ", y_pred, "\n")

#  Imprimiendo el resultado de manera más visible.
cat("Predicción con 5 de profundidad: ", y_pred[1:10], "\n")
```
# 4. Haga, al menos, 3 modelos más cambiando el parámetro de la profundidad del árbol. ¿Cuál es el mejor modelo para predecir el precio de las casas? 
```{r}

```
# 5. Compare los resultados con el modelo de regresión lineal de la hoja anterior, ¿cuál lo hizo mejor? 
```{r}

```