---
title: "Hoja4_MD"
author: "Alejandra Guzman, Mariana David, Jorge Caballeros"
date: "2023-03-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
## Librerias utilizadas
library(dplyr)
library(ggplot2)
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(ggplot2) #para color
library(caret)
library(nortest)
library(tidyverse)
library(rpart) #para analisis de arbol
library(rpart.plot)

library(caret)
library(rpart)
library(rpart.plot)
```

# 1. Descargar los data/cargar los datay usar los mismos conjuntos de entrenamiento y prueba  
Guardaremos train en un objeto llamado data
```{r}
library(caret)
library(rpart)
library(rpart.plot)

# Cargando data
data <- read.csv('./train.csv') # nolint

# Separando datade entrenamiento y prueba
set.seed(456)
train_index <- createDataPartition(data$SalePrice, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]

# Seleccionando variables predictoras y variable objetivo
predictors <- c("OverallCond")
response <- "OverallQual"

# Entrenando el modelo de árbol de decisión
model <- rpart(as.formula(paste(response, "~", paste(predictors, collapse = "+"))), data = train_data, method = "class", control = rpart.control(maxdepth = 4)) # nolint

# Graficando el árbol de decisión
rpart.plot(model, type = 4, extra = 101, under = TRUE, main = "Árbol de decisión") # nolint

# Haciendo predicciones con los datade prueba
predictions <- predict(model, test_data, type = "class")

# Evaluando la precisión del modelo
confusion_matrix <- table(predictions, test_data[, response])
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Resultado de la precision del modelo principal: ", accuracy, "\n")
```

# 2. Elabore un árbol de regresión para predecir el precio de las casas usando todas las variables
```{r}
library(rpart)
# Seleccionando solo las columnas numéricas
X <- data[, sapply(data, is.numeric)] # nolint
# Reemplazando los NaN por ceros.
X[is.na(X)] <- 0 # nolint
y <- data$SalePrice # Variable a predecir.
y[is.na(y)] <- 0 # Quitando los NaN de y.
arbol <- rpart(SalePrice ~ ., data = X, method = "anova", control = rpart.control(maxdepth = 2))  # nolint
# Prediciendo los valores.
score <- summary(arbol)$cp[length(summary(arbol)$cp)]
cat("Precisión del arbol de regresión:", score)
rpart.plot(arbol, extra = 1) # Visualizando el árbol.
```

# 3. Úselo para predecir y analice el resultado. ¿Qué tal lo hizo? 
```{r}
# Prediciendo el precio con el árbol de decisión.
y <- data[, sapply(data, is.numeric)]
y[is.na(y)] <- 0 # Convirtiendo los NaN a número.
y_pred <- predict(arbol, newdata = y) # Prediciendo el precio.
cat("Predicción con máximo de divisiones 5 (profundidad): ") # nolint
head(y_pred, 3)
```
# 4. Haga, al menos, 3 modelos más cambiando el parámetro de la profundidad del árbol. ¿Cuál es el mejor modelo para predecir el precio de las casas? 
```{r}
# Creando el modelo de árbol con profundidad de 3.
arbol <- rpart(SalePrice ~ ., data = data, method = "anova", control = rpart.control(maxdepth = 3)) # nolint
rpart.plot(arbol, type = 0, extra = 0, under = TRUE, main = "Árbol de decisión (PROFUNDIDAD: 3)") # nolint
y_pred <- predict(arbol, newdata = data) # Prediciendo los valores
cat("Precisión del árbol con divisiones maximas de 3:") # nolint
head(y_pred, 5) #Mostrar soslo los primeros 5 valores

# Creando el modelo de árbol con profundidad de 4.
arbol <- rpart(SalePrice ~ ., data = data, method = "anova", control = rpart.control(maxdepth = 4)) # nolint
rpart.plot(arbol, type = 0, extra = 0, under = TRUE, main = "Árbol de decisión (PROFUNDIDAD: 4)") # nolint
y_pred <- predict(arbol, newdata = data)
cat("Precisión del árbol con divisiones maximas de 4:") # nolint
head(y_pred, 5)

# Creando el modelo del árbol con profundidad de 6.
arbol <- rpart(SalePrice ~ ., data = data, method = "anova", control = rpart.control(maxdepth = 6)) # nolint
rpart.plot(arbol, type = 0, extra = 0, under = TRUE, main = "Árbol de decisión (PROFUNDIDAD: 6)") # nolint
y_pred <- predict(arbol, newdata = data)
cat("Precisión del árbol con divisiones máximas de  6:") # nolint
head(y_pred, 5)

# Creando el modelo del árbol con profundidad de 8.
arbol <- rpart(SalePrice ~ ., data = data, method = "anova", control = rpart.control(maxdepth = 8)) # nolint
rpart.plot(arbol, type = 0, extra = 0, under = TRUE, main = "Árbol de decisión (PROFUNDIDAD: 8)") # nolint
y_pred <- predict(arbol, newdata = data)
cat("Precisión del árbol con divisiones máximas de 8:") # nolint
head(y_pred, 5)
```
# 5. Compare los resultados con el modelo de regresión lineal de la hoja anterior, ¿cuál lo hizo mejor? 
Comparando el resultado de predicción de ahora podemos afirmar que el modelo de regresion lineal nos dio un mejor resultado ya que predijo de manera mas rapida y simple la modelacion entre la variable respuesta que neceistabamos como el precio de las casa. 


# 10 Entrene un modelo usando validación cruzada, prediga con él. ¿le fue mejor que al modelo anterior?


```{r}

library(caret)
library(mlbench)

data(PimaIndiansDiabetes)

set.seed(123)

# Dividir los datos en conjuntos de entrenamiento (70%) y prueba (30%)
training_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.7, list = FALSE)
training <- PimaIndiansDiabetes[training_index, ]
testing <- PimaIndiansDiabetes[-training_index, ]

# Definir la fórmula para el modelo
formula <- diabetes ~ .

# Entrenar el primer modelo con validación cruzada de 10 iteraciones
model1 <- train(formula, data = training, method = "glm", trControl = trainControl(method = "cv", number = 10))

# Hacer predicciones con el primer modelo
predictions1 <- predict(model1, newdata = testing)

# Evaluar el rendimiento del primer modelo
accuracy1 <- mean(predictions1 == testing$diabetes)
cat("La precisión del primer modelo es:", accuracy1, "\n")

# Entrenar el segundo modelo con validación cruzada de 10 iteraciones
model2 <- train(formula, data = training, method = "rf", trControl = trainControl(method = "cv", number = 10))

# Hacer predicciones con el segundo modelo
predictions2 <- predict(model2, newdata = testing)

# Evaluar el rendimiento del segundo modelo
accuracy2 <- mean(predictions2 == testing$diabetes)
cat("La precisión del segundo modelo es:", accuracy2, "\n")

```

Como podemos observar el segundo modelo tiene un mucho mejor rendimiento que el primero.



# 11 Haga al menos, 3 modelos más cambiando la profundidad del árbol. ¿Cuál funcionó mejor?

```{r}
library(rpart)
library(rpart.plot)
library(caret)

# Cargar los datos
data(iris)

# Definir el vector de índices de los pliegues de validación cruzada
folds <- createFolds(iris$Species, k = 10)

# Vector para guardar los resultados de la validación cruzada
cv_results <- c()

# Ajustar tres modelos de árbol con diferentes profundidades
for (i in 1:3) {
  
  # Definir el modelo
  model <- rpart(Species ~ ., data = iris, control = rpart.control(maxdepth = i))
  
  # Realizar la validación cruzada
  cv <- train(Species ~ ., data = iris, method = "rpart",
              trControl = trainControl(method = "cv", index = folds),
              tuneGrid = data.frame(cp = 0.01))
  
  # Guardar los resultados
  cv_results[i] <- cv$results$Accuracy
  
}

# Mostrar los resultados del accuracy de los tres modelos
cv_results

```

Los tres modelos tienen la misma precisión (accuracy) de 0.3333333, lo cual significa que no hay diferencia en términos de la capacidad del modelo para clasificar correctamente los datos de prueba. 



# 12 Repita los análisis usando random forest como algoritmo de predicción, explique sus resultados comparando ambos algoritmos

```{r}

# Cargar la librería de Random Forest
library(randomForest)

# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(123)
trainIndex <- createDataPartition(y = iris$Species, p = 0.8, list = FALSE)
training <- iris[trainIndex, ]
testing <- iris[-trainIndex, ]

# Entrenar un modelo de Random Forest
rf_model <- randomForest(Species ~ ., data = training)

# Realizar predicciones en el conjunto de prueba
rf_predictions <- predict(rf_model, testing)

# Evaluar la precisión del modelo
rf_accuracy <- mean(rf_predictions == testing$Species)
rf_accuracy


```

En general, el algoritmo de Random Forest tiende a ser más preciso que el árbol de decisión, ya que utiliza múltiples árboles de decisión para hacer predicciones en lugar de uno solo. Además, Random Forest tiene la capacidad de manejar mejor los datos desequilibrados y los datos con múltiples variables correlacionadas. Sin embargo, el tiempo de entrenamiento y evaluación del modelo de Random Forest puede ser mayor que el del árbol de decisión, especialmente en conjuntos de datos más grandes.


